{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Torch code\n",
        "Used to learn the weights and biases"
      ],
      "metadata": {
        "id": "Lcsj9r5qiVIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the weights and biases"
      ],
      "metadata": {
        "id": "p6CucIhBdN7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN quantized to INT8\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.fc1 = nn.Linear(1152, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.dequant(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "model.qconfig = torch.ao.quantization.default_qconfig\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model_quantized = torch.ao.quantization.prepare_qat(model,inplace=False)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "model_quantized = torch.ao.quantization.convert(model_quantized)\n",
        "model_quantized\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "VXMnTNCKulYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a35080-a486-4545-bf81-2fdaba8e2d78"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 485kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.42MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.54MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.5594\n",
            "Epoch 2, Loss: 1.4836\n",
            "Epoch 3, Loss: 1.4800\n",
            "Epoch 4, Loss: 1.4768\n",
            "Epoch 5, Loss: 1.4749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/utils.py:408: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fcl_weights=[torch.int_repr(model_quantized.fc1.weight().cpu()).numpy(),torch.int_repr(model_quantized.fc2.weight().cpu()).numpy()]\n",
        "fcl_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "85ilm5hR36On",
        "outputId": "15cb73c8-4ed0-402a-cf29-a828de269119"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ -95,   28,   -5, ...,  -94,   62, -117],\n",
              "        [  11, -104,  -63, ...,   87,   15,  114],\n",
              "        [ -30,  118,  126, ...,  -89,   -9,  -39],\n",
              "        ...,\n",
              "        [ -82,   11,   36, ...,  -93,  -26,  -69],\n",
              "        [  54,   74,   46, ..., -123,   82,  125],\n",
              "        [  71,  126,   -1, ...,   27,  -60,  -52]], dtype=int8),\n",
              " array([[-120,   -5,  -15, ...,   36,   23, -124],\n",
              "        [ -37,   23,  -15, ...,  -87,  -27,   15],\n",
              "        [ -58,   33,   42, ...,   24,   36, -124],\n",
              "        ...,\n",
              "        [ 106,  -77,   58, ..., -104,  -96,  -38],\n",
              "        [-123,  -49, -122, ...,   72,  -85,   34],\n",
              "        [ -82,  -85,   16, ...,   62,  -71,  105]], dtype=int8)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "biases=[model_quantized.fc1.bias().detach().cpu().numpy(),model_quantized.fc2.bias().detach().cpu().numpy()]\n",
        "fcl_biases=[np.int8(biases[0]*100),np.int8(biases[1]*100)]\n",
        "fcl_biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cvFjDYk47Slo",
        "outputId": "4d2f84be-58c8-48a5-f016-98669f2aed96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ 2,  0,  0,  0,  0,  0,  2, -1,  1,  1,  0,  2,  2,  1, -2, -1, -1,\n",
              "        -1,  0,  0,  1,  0,  2,  2,  0, -1, -2,  0, -1, -2, -2,  0,  0,  0,\n",
              "         0,  1, -2,  1, -2, -2,  1,  0,  1, -2,  0, -1,  1,  1,  0, -1,  1,\n",
              "         0,  2,  2, -2, -1,  2,  0,  0,  2,  2,  1,  2,  0,  1,  1,  0, -1,\n",
              "         1, -2,  0, -2,  2, -2, -1,  1,  2,  2,  2,  0,  0,  0,  1,  2, -1,\n",
              "         0, -2,  1,  0,  0,  1,  2,  2, -1,  0,  2, -2,  1,  2,  1, -1, -1,\n",
              "         2,  1,  1, -2,  2, -2,  1,  0, -2, -1,  0, -2,  1, -2,  0, -1,  0,\n",
              "        -2,  0, -1,  1, -2, -2,  1,  0,  2], dtype=int8),\n",
              " array([ 3,  1, -1,  4, -1,  2, -8, -2, -1,  8], dtype=int8)]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_weights=[torch.int_repr(model_quantized.conv1.weight().cpu()).numpy(),torch.int_repr(model_quantized.conv2.weight().cpu()).numpy()]\n",
        "conv_weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i1pNw1v54odF",
        "outputId": "6cc32714-1fd8-46c5-eaf2-4c8fe6275d9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[[  98,  106,  -30,  117,  -28],\n",
              "          [  26,  -62,   75,  112,  -94],\n",
              "          [ 111,   24,   94,   17,   62],\n",
              "          [ -18,   98,   19,  -60,   33],\n",
              "          [ -59,  -15,  -52,   85, -101]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[ -59,  -36,  -77,   12, -126],\n",
              "          [ 115, -108,   98,   21,  -41],\n",
              "          [  79,   20,  103,   14,  -40],\n",
              "          [  34,  -35,   54,  114,   74],\n",
              "          [ -56,   74,   23,   65,  -78]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[-126,  -49,  -98,  105,   37],\n",
              "          [  53,   40,   -2,  100,  -91],\n",
              "          [   8,  -87,   39,  -44,   39],\n",
              "          [ -27,  106,  -76,  -76,  -76],\n",
              "          [ 115,   43,  123, -105, -127]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[  43,   45, -106, -124,  -66],\n",
              "          [  87, -120, -111,   71,   69],\n",
              "          [ 105,  -96,  -93,   65,  111],\n",
              "          [  76,   20,   42,  121,  -82],\n",
              "          [ -58,   89,  -87,  -70,   93]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[  40,   41,  -54,   -2,  117],\n",
              "          [ -77,    1,   61,  -88,  124],\n",
              "          [ -64,  -31,  -35,  -83, -125],\n",
              "          [  72,   34, -119,  -82,  126],\n",
              "          [  49,   51,  -76,  -56,  -19]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[ -23,  -87,   11,   13,  -16],\n",
              "          [  18,  -51,   33,   48,  -67],\n",
              "          [-126,   67,   30,  -65,  123],\n",
              "          [ -58,   86,   65, -107,   82],\n",
              "          [-117,  -71,  -21,  -86,  125]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]]], dtype=int8),\n",
              " array([[[[-112,  -70,  -92],\n",
              "          [  63,  -86,  -11],\n",
              "          [  28,  -70,   37]],\n",
              " \n",
              "         [[-125,  -91, -116],\n",
              "          [ -39,  -46,   18],\n",
              "          [ -24,   60,  117]],\n",
              " \n",
              "         [[  46,  -50, -119],\n",
              "          [  46,  -63,   65],\n",
              "          [  85,   49,  120]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[  46,  108,    8],\n",
              "          [ -77,  105,   54],\n",
              "          [  84,  -86,   74]],\n",
              " \n",
              "         [[ -87,  126,  -54],\n",
              "          [  77,   26,   34],\n",
              "          [ -20,   52,  -53]],\n",
              " \n",
              "         [[-120,  -49,  100],\n",
              "          [ -34,   40,  -47],\n",
              "          [  96,   76,   45]]],\n",
              " \n",
              " \n",
              "        [[[ -65, -104,    5],\n",
              "          [ -75,  105, -123],\n",
              "          [  57,  127,   64]],\n",
              " \n",
              "         [[  43, -123,  123],\n",
              "          [ -22, -119,  126],\n",
              "          [ -52,   -9,  117]],\n",
              " \n",
              "         [[ -88,  -90,   21],\n",
              "          [ -17,   29, -107],\n",
              "          [   4,  -57,  -63]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-127,  105, -109],\n",
              "          [ 114,   -5, -113],\n",
              "          [  35,  -26, -115]],\n",
              " \n",
              "         [[ -46,   13,   99],\n",
              "          [ -39,   76,   16],\n",
              "          [   4,   24,  -84]],\n",
              " \n",
              "         [[-106,  -40, -119],\n",
              "          [ -59,    6,  -84],\n",
              "          [ -53,  -23,  -15]]],\n",
              " \n",
              " \n",
              "        [[[ -70,    6,  -18],\n",
              "          [  36,    6,  -64],\n",
              "          [ -44,   -1,  -80]],\n",
              " \n",
              "         [[  10,   -9,   49],\n",
              "          [  30,   95,   -4],\n",
              "          [ -94,   57,  -86]],\n",
              " \n",
              "         [[ -18,  -41,  -48],\n",
              "          [ -47,  117,   73],\n",
              "          [  35,  120, -116]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ -33,  -65,   44],\n",
              "          [ -76,   60,   70],\n",
              "          [  78,   33, -112]],\n",
              " \n",
              "         [[  92,  -40,  -38],\n",
              "          [ -14,   93,   98],\n",
              "          [  20,   61, -119]],\n",
              " \n",
              "         [[   0, -113,   43],\n",
              "          [ -91,  -45,   89],\n",
              "          [ 122,  -77,  -71]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[ -92,  113,  107],\n",
              "          [  48,  -17,   98],\n",
              "          [ -83,  -77,   70]],\n",
              " \n",
              "         [[  85,  -13,  117],\n",
              "          [  67,   62,  103],\n",
              "          [ 126,   89,  104]],\n",
              " \n",
              "         [[  12,  100,   69],\n",
              "          [ -63,   71,    9],\n",
              "          [ -44,   96,   33]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[  12,  -80,   49],\n",
              "          [ -70,  123, -113],\n",
              "          [  71,  -66,  -45]],\n",
              " \n",
              "         [[-119, -118, -121],\n",
              "          [  -2,  117,   58],\n",
              "          [  80,   29,  -49]],\n",
              " \n",
              "         [[ -50,  -38, -119],\n",
              "          [  70,  -38,  -72],\n",
              "          [  32,    0,   69]]],\n",
              " \n",
              " \n",
              "        [[[ -84,  127,  -51],\n",
              "          [  48,  116,   -7],\n",
              "          [-112, -123,  125]],\n",
              " \n",
              "         [[-119,  -47,   87],\n",
              "          [ -99,  119,   12],\n",
              "          [  40,   20,   14]],\n",
              " \n",
              "         [[  72, -110,   28],\n",
              "          [ -58,  121,  106],\n",
              "          [ -50,   71,  -22]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[   2, -123,  -89],\n",
              "          [  50,  -42,   -5],\n",
              "          [ -52,   83,  105]],\n",
              " \n",
              "         [[  92, -113,  -38],\n",
              "          [  62,   75,  -29],\n",
              "          [  70,   -4,   14]],\n",
              " \n",
              "         [[  86,   87,  -90],\n",
              "          [ -77,   45,   77],\n",
              "          [ -30,  113,  -15]]],\n",
              " \n",
              " \n",
              "        [[[ -65,  -13, -109],\n",
              "          [  40, -117,  118],\n",
              "          [ -97,   83,  -96]],\n",
              " \n",
              "         [[ -19,  -71,   65],\n",
              "          [  74, -119, -109],\n",
              "          [  17,   -3,    1]],\n",
              " \n",
              "         [[  39,  -25,  108],\n",
              "          [   9,  -59,   44],\n",
              "          [ -99,  -61,   37]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ -24,  100,  125],\n",
              "          [-115,   -2,   36],\n",
              "          [ 122,  -51,  -41]],\n",
              " \n",
              "         [[ -75,   33,   31],\n",
              "          [  -2,  -13,  -89],\n",
              "          [ -52,  -48,   33]],\n",
              " \n",
              "         [[  56,   60,  -97],\n",
              "          [ -10,  -24,  127],\n",
              "          [  92,  -95,  -70]]]], dtype=int8)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biases=[model_quantized.conv1.bias().detach().cpu().numpy(),model_quantized.conv2.bias().detach().cpu().numpy()]\n",
        "conv_biases=[np.int8(biases[0]*100),np.int8(biases[1]*100)]\n",
        "conv_biases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JQscR3pO6ItB",
        "outputId": "2ee6c6cd-4d5b-4b73-8d40-7b3a071a2318"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([ -4,   7, -17,  11,  -6, -15,   2,   9,  17, -12,  -9,   3,   5,\n",
              "          7,  10,  -4,  11,  14,  -5,  14,   9,  17, -11,  -9,  -5,   1,\n",
              "         12, -11,  10,  -7,  12,   0], dtype=int8),\n",
              " array([-4, -1, -5,  2, -2, -2,  0, -1,  4,  5, -5,  2,  0,  3, -2,  0,  0,\n",
              "         2,  2,  2,  0, -4, -3, -3, -5,  5, -2, -3, -2,  3, -3, -4],\n",
              "       dtype=int8)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# non quantized cnn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.fc1 = nn.Linear(1152, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.softmax(self.fc2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON4mscpaIaYC",
        "outputId": "9dafa350-fea0-46b8-e977-5f547ab85ada"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.6189\n",
            "Epoch 2, Loss: 1.5767\n",
            "Epoch 3, Loss: 1.5039\n",
            "Epoch 4, Loss: 1.4766\n",
            "Epoch 5, Loss: 1.4755\n",
            "Test Accuracy: 98.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(fcl_weights), type(fcl_biases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Bf7mqTLwBap",
        "outputId": "51ded83c-6e83-4ed4-f5c0-f4f60550a52d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(list, list)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fcl_weights), len(fcl_biases)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUuNfOKXwLaG",
        "outputId": "7e13d526-5574-4908-b172-3cc776531899"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fcl_weights[0]), len(fcl_weights[1]), len(fcl_biases[0]), len(fcl_biases[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYaFyEQSwPTG",
        "outputId": "172ce8bf-4a96-4f8c-a569-8ae61d3dbed8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 10, 128, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting to COE"
      ],
      "metadata": {
        "id": "KHGDyDJGimgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_coe(data, filename, radix = 2):\n",
        "    \"\"\"\n",
        "    COE file with 8-bit signed binary\n",
        "    \"\"\"\n",
        "    flat_data = data.flatten().tolist()\n",
        "\n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(f\"memory_initialization_radix={radix};\\n\")\n",
        "        f.write(\"memory_initialization_vector=\\n\")\n",
        "\n",
        "        for i, val in enumerate(flat_data):\n",
        "            bin_str = format(val & 0xFF, '08b')\n",
        "\n",
        "            if i < len(flat_data) - 1:\n",
        "                f.write(bin_str + \",\\n\")\n",
        "            else:\n",
        "                f.write(bin_str + \";\")"
      ],
      "metadata": {
        "id": "0AL8trdNvOme"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_coe(fcl_weights[0], \"fcl_weights_layer1.coe\", radix = 2)\n",
        "make_coe(fcl_weights[1], \"fcl_weights_layer2.coe\", radix = 2)\n",
        "\n",
        "make_coe(fcl_biases[0], \"fcl_biases_layer1.coe\", radix = 2)\n",
        "make_coe(fcl_biases[1], \"fcl_biases_layer2.coe\", radix = 2)"
      ],
      "metadata": {
        "id": "A1JWBW2rvSWv"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fcl_weights[0].flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3t9extgx2f0",
        "outputId": "a96be15d-1ee2-4d59-b446-ae7ca680a71f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-95,  28,  -5, ...,  27, -60, -52], dtype=int8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(fcl_weights[0].flatten().tolist()) == 128*1152"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpUD4n_5yvpA",
        "outputId": "62990645-e582-4858-fa17-6cba688fe720"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}