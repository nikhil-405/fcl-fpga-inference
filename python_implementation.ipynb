{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcsj9r5qiVIA"
      },
      "source": [
        "# Torch code\n",
        "Used to learn the weights and biases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6CucIhBdN7V"
      },
      "source": [
        "## Training the weights and biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXMnTNCKulYJ",
        "outputId": "75f36975-8037-457d-ec5a-fe4f98a4f964"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 14.7MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 482kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.94MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.5589\n",
            "Epoch 2, Loss: 1.4825\n",
            "Epoch 3, Loss: 1.4793\n",
            "Epoch 4, Loss: 1.4769\n",
            "Epoch 5, Loss: 1.4756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/ao/quantization/utils.py:408: UserWarning: must run observer before calling calculate_qparams. Returning default values.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 98.85%\n"
          ]
        }
      ],
      "source": [
        "# CNN quantized to INT8\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.fc1 = nn.Linear(1152, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "        self.quant = torch.quantization.QuantStub()\n",
        "        self.dequant = torch.quantization.DeQuantStub()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant(x)\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = self.dequant(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "model.qconfig = torch.ao.quantization.default_qconfig\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "model_quantized = torch.ao.quantization.prepare_qat(model,inplace=False)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "model_quantized = torch.ao.quantization.convert(model_quantized)\n",
        "model_quantized\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "85ilm5hR36On",
        "outputId": "d83b58b1-9e52-433f-d202-3a1813a710ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ -95,   28,   -5, ...,  -94,   62, -117],\n",
              "        [  11, -104,  -63, ...,   87,   15,  114],\n",
              "        [ -30,  118,  126, ...,  -89,   -9,  -39],\n",
              "        ...,\n",
              "        [ -82,   11,   36, ...,  -93,  -26,  -69],\n",
              "        [  54,   74,   46, ..., -123,   82,  125],\n",
              "        [  71,  126,   -1, ...,   27,  -60,  -52]], dtype=int8),\n",
              " array([[-120,   -5,  -15, ...,   36,   23, -124],\n",
              "        [ -37,   23,  -15, ...,  -87,  -27,   15],\n",
              "        [ -58,   33,   42, ...,   24,   36, -124],\n",
              "        ...,\n",
              "        [ 106,  -77,   58, ..., -104,  -96,  -38],\n",
              "        [-123,  -49, -122, ...,   72,  -85,   34],\n",
              "        [ -82,  -85,   16, ...,   62,  -71,  105]], dtype=int8)]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fcl_weights=[torch.int_repr(model_quantized.fc1.weight().cpu()).numpy(),torch.int_repr(model_quantized.fc2.weight().cpu()).numpy()]\n",
        "fcl_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cvFjDYk47Slo",
        "outputId": "a015e0ab-e2a5-4742-e0d4-99a0e14aadbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([ 2,  0,  0,  0,  0,  0,  2, -1,  1,  1,  0,  2,  2,  1, -2, -1, -1,\n",
              "        -1,  0,  0,  1,  0,  2,  2,  0, -1, -2,  0, -1, -2, -2,  0,  0,  0,\n",
              "         0,  1, -2,  1, -2, -2,  1,  0,  1, -2,  0, -1,  1,  1,  0, -1,  1,\n",
              "         0,  2,  2, -2, -1,  2,  0,  0,  2,  2,  1,  2,  0,  1,  1,  0, -1,\n",
              "         1, -2,  0, -2,  2, -2, -1,  1,  2,  2,  2,  0,  0,  0,  1,  2, -1,\n",
              "         0, -2,  1,  0,  0,  1,  2,  2, -1,  0,  2, -2,  1,  2,  1, -1, -1,\n",
              "         2,  1,  1, -2,  2, -2,  1,  0, -2, -1,  0, -2,  1, -2,  0, -1,  0,\n",
              "        -2,  0, -1,  1, -2, -2,  1,  0,  2], dtype=int8),\n",
              " array([ 3,  1, -1,  4, -1,  2, -8, -2, -1,  8], dtype=int8)]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "biases=[model_quantized.fc1.bias().detach().cpu().numpy(),model_quantized.fc2.bias().detach().cpu().numpy()]\n",
        "fcl_biases=[np.int8(biases[0]*100),np.int8(biases[1]*100)]\n",
        "fcl_biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "i1pNw1v54odF",
        "outputId": "9425e943-02af-411b-af1c-381994db2af2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[[[  98,  106,  -30,  117,  -28],\n",
              "          [  26,  -62,   75,  112,  -94],\n",
              "          [ 111,   24,   94,   17,   62],\n",
              "          [ -18,   98,   19,  -60,   33],\n",
              "          [ -59,  -15,  -52,   85, -101]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[ -59,  -36,  -77,   12, -126],\n",
              "          [ 115, -108,   98,   21,  -41],\n",
              "          [  79,   20,  103,   14,  -40],\n",
              "          [  34,  -35,   54,  114,   74],\n",
              "          [ -56,   74,   23,   65,  -78]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[-126,  -49,  -98,  105,   37],\n",
              "          [  53,   40,   -2,  100,  -91],\n",
              "          [   8,  -87,   39,  -44,   39],\n",
              "          [ -27,  106,  -76,  -76,  -76],\n",
              "          [ 115,   43,  123, -105, -127]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[  43,   45, -106, -124,  -66],\n",
              "          [  87, -120, -111,   71,   69],\n",
              "          [ 105,  -96,  -93,   65,  111],\n",
              "          [  76,   20,   42,  121,  -82],\n",
              "          [ -58,   89,  -87,  -70,   93]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[  40,   41,  -54,   -2,  117],\n",
              "          [ -77,    1,   61,  -88,  124],\n",
              "          [ -64,  -31,  -35,  -83, -125],\n",
              "          [  72,   34, -119,  -82,  126],\n",
              "          [  49,   51,  -76,  -56,  -19]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]],\n",
              " \n",
              " \n",
              "        [[[ -23,  -87,   11,   13,  -16],\n",
              "          [  18,  -51,   33,   48,  -67],\n",
              "          [-126,   67,   30,  -65,  123],\n",
              "          [ -58,   86,   65, -107,   82],\n",
              "          [-117,  -71,  -21,  -86,  125]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]],\n",
              " \n",
              "         [[   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0],\n",
              "          [   0,    0,    0,    0,    0]]]], dtype=int8),\n",
              " array([[[[-112,  -70,  -92],\n",
              "          [  63,  -86,  -11],\n",
              "          [  28,  -70,   37]],\n",
              " \n",
              "         [[-125,  -91, -116],\n",
              "          [ -39,  -46,   18],\n",
              "          [ -24,   60,  117]],\n",
              " \n",
              "         [[  46,  -50, -119],\n",
              "          [  46,  -63,   65],\n",
              "          [  85,   49,  120]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[  46,  108,    8],\n",
              "          [ -77,  105,   54],\n",
              "          [  84,  -86,   74]],\n",
              " \n",
              "         [[ -87,  126,  -54],\n",
              "          [  77,   26,   34],\n",
              "          [ -20,   52,  -53]],\n",
              " \n",
              "         [[-120,  -49,  100],\n",
              "          [ -34,   40,  -47],\n",
              "          [  96,   76,   45]]],\n",
              " \n",
              " \n",
              "        [[[ -65, -104,    5],\n",
              "          [ -75,  105, -123],\n",
              "          [  57,  127,   64]],\n",
              " \n",
              "         [[  43, -123,  123],\n",
              "          [ -22, -119,  126],\n",
              "          [ -52,   -9,  117]],\n",
              " \n",
              "         [[ -88,  -90,   21],\n",
              "          [ -17,   29, -107],\n",
              "          [   4,  -57,  -63]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[-127,  105, -109],\n",
              "          [ 114,   -5, -113],\n",
              "          [  35,  -26, -115]],\n",
              " \n",
              "         [[ -46,   13,   99],\n",
              "          [ -39,   76,   16],\n",
              "          [   4,   24,  -84]],\n",
              " \n",
              "         [[-106,  -40, -119],\n",
              "          [ -59,    6,  -84],\n",
              "          [ -53,  -23,  -15]]],\n",
              " \n",
              " \n",
              "        [[[ -70,    6,  -18],\n",
              "          [  36,    6,  -64],\n",
              "          [ -44,   -1,  -80]],\n",
              " \n",
              "         [[  10,   -9,   49],\n",
              "          [  30,   95,   -4],\n",
              "          [ -94,   57,  -86]],\n",
              " \n",
              "         [[ -18,  -41,  -48],\n",
              "          [ -47,  117,   73],\n",
              "          [  35,  120, -116]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ -33,  -65,   44],\n",
              "          [ -76,   60,   70],\n",
              "          [  78,   33, -112]],\n",
              " \n",
              "         [[  92,  -40,  -38],\n",
              "          [ -14,   93,   98],\n",
              "          [  20,   61, -119]],\n",
              " \n",
              "         [[   0, -113,   43],\n",
              "          [ -91,  -45,   89],\n",
              "          [ 122,  -77,  -71]]],\n",
              " \n",
              " \n",
              "        ...,\n",
              " \n",
              " \n",
              "        [[[ -92,  113,  107],\n",
              "          [  48,  -17,   98],\n",
              "          [ -83,  -77,   70]],\n",
              " \n",
              "         [[  85,  -13,  117],\n",
              "          [  67,   62,  103],\n",
              "          [ 126,   89,  104]],\n",
              " \n",
              "         [[  12,  100,   69],\n",
              "          [ -63,   71,    9],\n",
              "          [ -44,   96,   33]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[  12,  -80,   49],\n",
              "          [ -70,  123, -113],\n",
              "          [  71,  -66,  -45]],\n",
              " \n",
              "         [[-119, -118, -121],\n",
              "          [  -2,  117,   58],\n",
              "          [  80,   29,  -49]],\n",
              " \n",
              "         [[ -50,  -38, -119],\n",
              "          [  70,  -38,  -72],\n",
              "          [  32,    0,   69]]],\n",
              " \n",
              " \n",
              "        [[[ -84,  127,  -51],\n",
              "          [  48,  116,   -7],\n",
              "          [-112, -123,  125]],\n",
              " \n",
              "         [[-119,  -47,   87],\n",
              "          [ -99,  119,   12],\n",
              "          [  40,   20,   14]],\n",
              " \n",
              "         [[  72, -110,   28],\n",
              "          [ -58,  121,  106],\n",
              "          [ -50,   71,  -22]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[   2, -123,  -89],\n",
              "          [  50,  -42,   -5],\n",
              "          [ -52,   83,  105]],\n",
              " \n",
              "         [[  92, -113,  -38],\n",
              "          [  62,   75,  -29],\n",
              "          [  70,   -4,   14]],\n",
              " \n",
              "         [[  86,   87,  -90],\n",
              "          [ -77,   45,   77],\n",
              "          [ -30,  113,  -15]]],\n",
              " \n",
              " \n",
              "        [[[ -65,  -13, -109],\n",
              "          [  40, -117,  118],\n",
              "          [ -97,   83,  -96]],\n",
              " \n",
              "         [[ -19,  -71,   65],\n",
              "          [  74, -119, -109],\n",
              "          [  17,   -3,    1]],\n",
              " \n",
              "         [[  39,  -25,  108],\n",
              "          [   9,  -59,   44],\n",
              "          [ -99,  -61,   37]],\n",
              " \n",
              "         ...,\n",
              " \n",
              "         [[ -24,  100,  125],\n",
              "          [-115,   -2,   36],\n",
              "          [ 122,  -51,  -41]],\n",
              " \n",
              "         [[ -75,   33,   31],\n",
              "          [  -2,  -13,  -89],\n",
              "          [ -52,  -48,   33]],\n",
              " \n",
              "         [[  56,   60,  -97],\n",
              "          [ -10,  -24,  127],\n",
              "          [  92,  -95,  -70]]]], dtype=int8)]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_weights=[torch.int_repr(model_quantized.conv1.weight().cpu()).numpy(),torch.int_repr(model_quantized.conv2.weight().cpu()).numpy()]\n",
        "conv_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JQscR3pO6ItB",
        "outputId": "5019f467-8162-481a-fbd9-eb07ce55fece"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([ -4,   7, -17,  11,  -6, -15,   2,   9,  17, -12,  -9,   3,   5,\n",
              "          7,  10,  -4,  11,  14,  -5,  14,   9,  17, -11,  -9,  -5,   1,\n",
              "         12, -11,  10,  -7,  12,   0], dtype=int8),\n",
              " array([-4, -1, -5,  2, -2, -2,  0, -1,  4,  5, -5,  2,  0,  3, -2,  0,  0,\n",
              "         2,  2,  2,  0, -4, -3, -3, -5,  5, -2, -3, -2,  3, -3, -4],\n",
              "       dtype=int8)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "biases=[model_quantized.conv1.bias().detach().cpu().numpy(),model_quantized.conv2.bias().detach().cpu().numpy()]\n",
        "conv_biases=[np.int8(biases[0]*100),np.int8(biases[1]*100)]\n",
        "conv_biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ON4mscpaIaYC",
        "outputId": "a802ae26-e603-4e09-9311-f6946edaa179"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.6354\n",
            "Epoch 2, Loss: 1.5186\n",
            "Epoch 3, Loss: 1.4794\n",
            "Epoch 4, Loss: 1.4768\n",
            "Epoch 5, Loss: 1.4739\n",
            "Test Accuracy: 98.30%\n"
          ]
        }
      ],
      "source": [
        "# non quantized cnn\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the CNN model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.fc1 = nn.Linear(1152, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.softmax(self.fc2(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "# Load the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Model, Loss, and Optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHGDyDJGimgg"
      },
      "source": [
        "# Implementation in vanilla Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg55VlwqYZDf"
      },
      "source": [
        "## Sequential inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGuvOKsmZwu9"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkjSdjtpZT-c"
      },
      "outputs": [],
      "source": [
        "def mat_vec_mul(matrix, vector):\n",
        "    result = []\n",
        "    for row in matrix:\n",
        "        dot = 0\n",
        "        for i in range(len(vector)):\n",
        "            dot += row[i] * vector[i]\n",
        "        result.append(dot)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYtJRXhJZyt5"
      },
      "outputs": [],
      "source": [
        "def vec_add(vec1, vec2):\n",
        "    if len(vec1) != len(vec2):\n",
        "        return 0\n",
        "\n",
        "    sum_ = [0]*len(vec1)\n",
        "    for i in range(len(vec1)):\n",
        "        sum_[i] = vec1[i] + vec2[i]\n",
        "    return sum_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wE-Qj2p6Z0WE"
      },
      "outputs": [],
      "source": [
        "def relu(vector):\n",
        "    return [x if x > 0 else 0 for x in vector]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvyTG-8eZ2G8"
      },
      "outputs": [],
      "source": [
        "def softmax(vector):\n",
        "    vector = [float(x) for x in vector]\n",
        "    max_val = max(vector)\n",
        "    exps = [math.exp(x - max_val) for x in vector] # numerical stability\n",
        "    sum_exps = sum(exps)\n",
        "    return [e / sum_exps for e in exps]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3scfm9l1aTHA"
      },
      "outputs": [],
      "source": [
        "def forward(x, weights, biases):\n",
        "    # fc1 = ReLU(W1 * x + b1)\n",
        "    fc1_linear = vec_add(mat_vec_mul(weights[0], x), biases[0])\n",
        "    fc1_activated = relu(fc1_linear)\n",
        "\n",
        "    # fc2 = softmax(W2 * fc1_activated + b2)\n",
        "    fc2_linear = vec_add(mat_vec_mul(weights[1], fc1_activated), biases[1])\n",
        "    output = softmax(fc2_linear)\n",
        "\n",
        "    return output # list of size 10 containing probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07IwrhD8YYrp",
        "outputId": "dede6b88-e366-42d2-ad12-72a5c058cb6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "([array([[ -95,   28,   -5, ...,  -94,   62, -117],\n",
              "         [  11, -104,  -63, ...,   87,   15,  114],\n",
              "         [ -30,  118,  126, ...,  -89,   -9,  -39],\n",
              "         ...,\n",
              "         [ -82,   11,   36, ...,  -93,  -26,  -69],\n",
              "         [  54,   74,   46, ..., -123,   82,  125],\n",
              "         [  71,  126,   -1, ...,   27,  -60,  -52]], dtype=int8),\n",
              "  array([[-120,   -5,  -15, ...,   36,   23, -124],\n",
              "         [ -37,   23,  -15, ...,  -87,  -27,   15],\n",
              "         [ -58,   33,   42, ...,   24,   36, -124],\n",
              "         ...,\n",
              "         [ 106,  -77,   58, ..., -104,  -96,  -38],\n",
              "         [-123,  -49, -122, ...,   72,  -85,   34],\n",
              "         [ -82,  -85,   16, ...,   62,  -71,  105]], dtype=int8)],\n",
              " list)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fcl_weights, type(fcl_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aw7-EG5va75b"
      },
      "outputs": [],
      "source": [
        "py_fcl_weights = [w.tolist() for w in fcl_weights]\n",
        "py_fcl_biases = [b.tolist() for b in fcl_biases]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhjCDXmxbH7Q",
        "outputId": "48dd8308-c3e1-4511-f93a-035759f1eb02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 128, 10)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(py_fcl_biases), len(py_fcl_biases[0]), len(py_fcl_biases[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOVGsI85bJxk",
        "outputId": "b4b9d490-4c07-47c9-b32e-659d9547b88e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output probabilities:\n",
            "Class 0: 0.0000\n",
            "Class 1: 1.0000\n",
            "Class 2: 0.0000\n",
            "Class 3: 0.0000\n",
            "Class 4: 0.0000\n",
            "Class 5: 0.0000\n",
            "Class 6: 0.0000\n",
            "Class 7: 0.0000\n",
            "Class 8: 0.0000\n",
            "Class 9: 0.0000\n",
            "-----------------------\n",
            "Predicted class: 1\n"
          ]
        }
      ],
      "source": [
        "# Sample run\n",
        "import random\n",
        "dummy_input = [random.randint(-128, 127) for _ in range(1152)] # cnn outputs a vector of size 1152\n",
        "\n",
        "probabilities = forward(dummy_input, py_fcl_weights, py_fcl_biases)\n",
        "\n",
        "print(\"Output probabilities:\")\n",
        "for i, prob in enumerate(probabilities):\n",
        "    print(f\"Class {i}: {prob:.4f}\")\n",
        "\n",
        "print(\"-----------------------\")\n",
        "\n",
        "class_ = 0\n",
        "for i in range(len(probabilities)):\n",
        "    if probabilities[i] > probabilities[class_]:\n",
        "        class_ = i\n",
        "\n",
        "print(f\"Predicted class: {class_}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxSONpu-dEld"
      },
      "source": [
        "## Single input parallelized inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvWvKkf7dF8V"
      },
      "outputs": [],
      "source": [
        "# we can parallelize the inference by using multiprocessing for matrix multiplication\n",
        "\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def dot_product(vector1, vector2):\n",
        "    dot = 0\n",
        "    for i in range(len(vector1)):\n",
        "        dot += vector1[i] * vector2[i]\n",
        "    return dot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94tIqa_zd1LF"
      },
      "outputs": [],
      "source": [
        "def mat_vec_mul_2(matrix, vector, num_workers = None):\n",
        "    args = [(row, vector) for row in matrix]\n",
        "    with Pool(processes=num_workers) as pool:\n",
        "        result = pool.map(dot_product, args)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUz7Duxah-NQ"
      },
      "source": [
        "## Batch of inputs parallelization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljOj-arSiAe-"
      },
      "outputs": [],
      "source": [
        "# we can parallelize inference in case of a batch of inputs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
